/* Generated by: JavaCC 21 Parser Generator. NewAwkParser.java */
package de.compilerbau.NewAwkCompiler.javacc21;

import java.util.*;
import java.util.concurrent.CancellationException;
import java.util.logging.*;
import java.io.*;
import static de.compilerbau.NewAwkCompiler.javacc21.NewAwkConstants.TokenType.*;
@SuppressWarnings("unused")
public class NewAwkParser implements NewAwkConstants {
    private static String testToken;
    public static void main(String[] args) throws ParseException, FileNotFoundException {
        File file= new File(".\\src\\main\\java\\de\\compilerbau\\NewAwkCompiler\\NewAwkTest.txt");
        FileInputStream is= new FileInputStream(file);
        NewAwkParser parser= new NewAwkParser(new BufferedInputStream(is));
        parser.program();
        parser.printTokens(testToken);
    }

    private void printTokens(String testToken) {
        System.out.println("Test: "+testToken);
    }

    private static final java.util.logging.Logger LOGGER= Logger.getLogger(NewAwkParser.class.getName());
    static {
        LOGGER.setLevel(Level.FINEST);
    }
    public static void setLogLevel(Level level) {
        LOGGER.setLevel(level);
        Logger.getGlobal().getParent().getHandlers()[0].setLevel(level);
    }

    // The last token successfully "consumed"     
    Token current_token;
    private TokenType nextTokenType;
    private Token currentLookaheadToken;
    private int remainingLookahead;
    private TokenType upToTokenType;
    private EnumSet<TokenType> upToFirstSet;
    private Token lastParsedToken;
    //private Token nextToken; //REVISIT
    //private EnumSet<Token> currentFollowSet;
    private boolean cancelled;
    public void cancel() {
        cancelled= true;
    }

    public boolean isCancelled() {
        return cancelled;
    }

    /** Generated Lexer. */
    public NewAwkLexer token_source;
    public void setInputSource(String inputSource) {
        token_source.setInputSource(inputSource);
    }

    String getInputSource() {
        return token_source.getInputSource();
    }

    //=================================
    // Generated constructors
    //=================================
    public NewAwkParser(String inputSource, CharSequence content) {
        this(new NewAwkLexer(inputSource, content));
    }

    public NewAwkParser(CharSequence content) {
        this("input", content);
    }

    public NewAwkParser(java.io.InputStream stream) {
        this(new InputStreamReader(stream));
    }

    public NewAwkParser(Reader reader) {
        this(new NewAwkLexer(reader));
    }

    /** Constructor with user supplied Lexer. */
    public NewAwkParser(NewAwkLexer lexer) {
        token_source= lexer;
        current_token= new Token();
    }

    final public Token getNextToken() {
        if (current_token.getNext()!=null) current_token= current_token.getNext();
        else {
            Token nextToken= token_source.getNextToken();
            current_token.setNext(nextToken);
            current_token= nextToken;
        }
        return current_token;
    }

    /** Get the specific Token index ahead in the stream. */
    final public Token getToken(int index) {
        Token t= current_token;
        for (int i= 0; i<index; i++) {
            if (t.getNext()!=null) t= t.getNext();
            else {
                Token nextToken= token_source.getNextToken();
                t.setNext(nextToken);
                t= nextToken;
            }
        }
        return t;
    }

    private final boolean setNextTokenType() {
        if (current_token.getNext()== null) {
            Token nextToken= token_source.getNextToken();
            current_token.setNext(nextToken);
        }
        nextTokenType= current_token.getNext().getType();
        return true;
    }

    private final TokenType nextTokenType() {
        setNextTokenType();
        return nextTokenType;
    }

    private final boolean resetScanAhead(int amount, EnumSet<TokenType> upToFirstSet) {
        resetScanAhead(amount);
        this.upToFirstSet= upToFirstSet;
        return true;
    }

    private final boolean resetScanAhead(int amount, TokenType upToTokenType) {
        resetScanAhead(amount);
        this.upToTokenType= upToTokenType;
        return true;
    }

    private final boolean resetScanAhead(int amount) {
        currentLookaheadToken= current_token;
        remainingLookahead= amount;
        this.upToTokenType= null;
        this.upToFirstSet= null;
        setNextTokenType();
        return true;
    }

    /*
    ==============================================================================================
    Parser Rules and AST generation are defined/handled in this section
    ==============================================================================================
*/
    // NewAwkParser.jjt, line 107
    final public Node program() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 107 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean program1forced= false;
        Program program1= null;
        if (buildTree) {
            program1= new Program();
            openNodeScope(program1);
        }
        ParseException parseException1= null;
        int callStackSize1= parsingStack.size();
        try {
            // Code for NonTerminal specified on line 109 of NewAwkParser.jjt
            pushOntoCallStack("program", "NewAwkParser.jjt", 109, 5);
            try {
                fieldOrMethods();
            }
            finally {
                popCallStack();
            }
            // Code for EndOfFile specified on line 110 of NewAwkParser.jjt
            consumeToken(TokenType.EOF);
            // Code for CodeBlock specified on line 111 of NewAwkParser.jjt
            return program1;
        }
        catch(ParseException e) {
            parseException1= e;
            throw e;
        }
        finally {
            if (parseException1== null) {
                restoreCallStack(callStackSize1);
            }
            if (buildTree) {
                if (parseException1== null) {
                    closeNodeScope(program1, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException1.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 113
    final public void fieldOrMethods() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 113 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean fieldOrMethods2forced= false;
        FieldOrMethods fieldOrMethods2= null;
        if (buildTree) {
            fieldOrMethods2= new FieldOrMethods();
            openNodeScope(fieldOrMethods2);
        }
        ParseException parseException2= null;
        int callStackSize2= parsingStack.size();
        try {
            // Code for OneOrMore specified on line 115 of NewAwkParser.jjt
            boolean inFirst0= true;
            do {
                // Code for ExpansionChoice specified on line 115 of NewAwkParser.jjt
                if (resetScanAhead(2147483647)&&check$NewAwkParser_jjt$line_115$column_7()) {
                    // Code for NonTerminal specified on line 115 of NewAwkParser.jjt
                    pushOntoCallStack("fieldOrMethods", "NewAwkParser.jjt", 115, 12);
                    try {
                        fieldDeclarationAndAssignment();
                    }
                    finally {
                        popCallStack();
                    }
                }
                else if (resetScanAhead(1)&&nextTokenType== TokenType.DataType||nextTokenType== TokenType.ArrayType||nextTokenType== TokenType.VOID) {
                    // Code for NonTerminal specified on line 115 of NewAwkParser.jjt
                    pushOntoCallStack("fieldOrMethods", "NewAwkParser.jjt", 115, 46);
                    try {
                        methodDeclaration();
                    }
                    finally {
                        popCallStack();
                    }
                }
                else if (inFirst0) {
                    pushOntoCallStack("fieldOrMethods", "NewAwkParser.jjt", 115, 7);
                    throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_115$column_7, parsingStack);
                }
                else {
                    break;
                }
                inFirst0= false;
            }
            while (true);
            if (trace_enabled) LOGGER.info("Exiting normally from fieldOrMethods");
        }
        catch(ParseException e) {
            parseException2= e;
            throw e;
        }
        finally {
            if (parseException2== null) {
                restoreCallStack(callStackSize2);
            }
            if (buildTree) {
                if (parseException2== null) {
                    closeNodeScope(fieldOrMethods2, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException2.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 117
    final public void fieldDeclarationAndAssignment() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 117 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean fieldDeclarationAndAssignment3forced= false;
        FieldDeclarationAndAssignment fieldDeclarationAndAssignment3= null;
        if (buildTree) {
            fieldDeclarationAndAssignment3= new FieldDeclarationAndAssignment();
            openNodeScope(fieldDeclarationAndAssignment3);
        }
        ParseException parseException3= null;
        int callStackSize3= parsingStack.size();
        try {
            // Code for RegexpRef specified on line 119 of NewAwkParser.jjt
            consumeToken(TokenType.DataType);
            // Code for NonTerminal specified on line 119 of NewAwkParser.jjt
            pushOntoCallStack("fieldDeclarationAndAssignment", "NewAwkParser.jjt", 119, 16);
            try {
                assignment();
            }
            finally {
                popCallStack();
            }
            if (trace_enabled) LOGGER.info("Exiting normally from fieldDeclarationAndAssignment");
        }
        catch(ParseException e) {
            parseException3= e;
            throw e;
        }
        finally {
            if (parseException3== null) {
                restoreCallStack(callStackSize3);
            }
            if (buildTree) {
                if (parseException3== null) {
                    closeNodeScope(fieldDeclarationAndAssignment3, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException3.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 121
    final public void assignment() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 121 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean assignment4forced= false;
        Assignment assignment4= null;
        if (buildTree) {
            assignment4= new Assignment();
            openNodeScope(assignment4);
        }
        ParseException parseException4= null;
        int callStackSize4= parsingStack.size();
        try {
            // Code for RegexpRef specified on line 123 of NewAwkParser.jjt
            consumeToken(TokenType.Bezeichner);
            // Code for RegexpRef specified on line 123 of NewAwkParser.jjt
            consumeToken(TokenType.Zuweisung);
            // Code for ExpansionChoice specified on line 124 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.Bezeichner) {
                // Code for RegexpRef specified on line 124 of NewAwkParser.jjt
                consumeToken(TokenType.Bezeichner);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.IntegerLiteral) {
                // Code for RegexpRef specified on line 124 of NewAwkParser.jjt
                consumeToken(TokenType.IntegerLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.DoubleLiteral) {
                // Code for RegexpRef specified on line 124 of NewAwkParser.jjt
                consumeToken(TokenType.DoubleLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.CharLiteral) {
                // Code for RegexpRef specified on line 124 of NewAwkParser.jjt
                consumeToken(TokenType.CharLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.BooleanValue) {
                // Code for RegexpRef specified on line 124 of NewAwkParser.jjt
                consumeToken(TokenType.BooleanValue);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.StringLiteral) {
                // Code for RegexpRef specified on line 124 of NewAwkParser.jjt
                consumeToken(TokenType.StringLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.NullLiteral) {
                // Code for RegexpRef specified on line 124 of NewAwkParser.jjt
                consumeToken(TokenType.NullLiteral);
            }
            else {
                pushOntoCallStack("assignment", "NewAwkParser.jjt", 124, 6);
                throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_124$column_6, parsingStack);
            }
            // Code for RegexpRef specified on line 125 of NewAwkParser.jjt
            consumeToken(TokenType.SEMICOLON);
            if (trace_enabled) LOGGER.info("Exiting normally from assignment");
        }
        catch(ParseException e) {
            parseException4= e;
            throw e;
        }
        finally {
            if (parseException4== null) {
                restoreCallStack(callStackSize4);
            }
            if (buildTree) {
                if (parseException4== null) {
                    closeNodeScope(assignment4, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException4.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 127
    final public void arrayAssignment() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 127 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean arrayAssignment5forced= false;
        ArrayAssignment arrayAssignment5= null;
        if (buildTree) {
            arrayAssignment5= new ArrayAssignment();
            openNodeScope(arrayAssignment5);
        }
        ParseException parseException5= null;
        int callStackSize5= parsingStack.size();
        try {
            // Code for RegexpRef specified on line 129 of NewAwkParser.jjt
            consumeToken(TokenType.ArrayType);
            // Code for NonTerminal specified on line 129 of NewAwkParser.jjt
            pushOntoCallStack("arrayAssignment", "NewAwkParser.jjt", 129, 17);
            try {
                assignment();
            }
            finally {
                popCallStack();
            }
            if (trace_enabled) LOGGER.info("Exiting normally from arrayAssignment");
        }
        catch(ParseException e) {
            parseException5= e;
            throw e;
        }
        finally {
            if (parseException5== null) {
                restoreCallStack(callStackSize5);
            }
            if (buildTree) {
                if (parseException5== null) {
                    closeNodeScope(arrayAssignment5, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException5.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 131
    final public void methodDeclaration() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 131 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean methodDeclaration6forced= false;
        Method methodDeclaration6= null;
        if (buildTree) {
            methodDeclaration6= new Method();
            openNodeScope(methodDeclaration6);
        }
        ParseException parseException6= null;
        int callStackSize6= parsingStack.size();
        try {
            // Code for NonTerminal specified on line 133 of NewAwkParser.jjt
            pushOntoCallStack("methodDeclaration", "NewAwkParser.jjt", 133, 5);
            try {
                methodSignature();
            }
            finally {
                popCallStack();
            }
            // Code for NonTerminal specified on line 134 of NewAwkParser.jjt
            pushOntoCallStack("methodDeclaration", "NewAwkParser.jjt", 134, 5);
            try {
                methodBody();
            }
            finally {
                popCallStack();
            }
            if (trace_enabled) LOGGER.info("Exiting normally from methodDeclaration");
        }
        catch(ParseException e) {
            parseException6= e;
            throw e;
        }
        finally {
            if (parseException6== null) {
                restoreCallStack(callStackSize6);
            }
            if (buildTree) {
                if (parseException6== null) {
                    closeNodeScope(methodDeclaration6, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException6.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 136
    final public void methodSignature() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 136 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean methodSignature7forced= false;
        MethodSignature methodSignature7= null;
        if (buildTree) {
            methodSignature7= new MethodSignature();
            openNodeScope(methodSignature7);
        }
        ParseException parseException7= null;
        int callStackSize7= parsingStack.size();
        try {
            // Code for ExpansionChoice specified on line 138 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.DataType) {
                // Code for RegexpRef specified on line 138 of NewAwkParser.jjt
                consumeToken(TokenType.DataType);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.ArrayType) {
                // Code for RegexpRef specified on line 138 of NewAwkParser.jjt
                consumeToken(TokenType.ArrayType);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.VOID) {
                // Code for RegexpRef specified on line 138 of NewAwkParser.jjt
                consumeToken(TokenType.VOID);
            }
            else {
                pushOntoCallStack("methodSignature", "NewAwkParser.jjt", 138, 6);
                throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_138$column_6, parsingStack);
            }
            // Code for RegexpRef specified on line 138 of NewAwkParser.jjt
            consumeToken(TokenType.Bezeichner);
            // Code for RegexpRef specified on line 138 of NewAwkParser.jjt
            consumeToken(TokenType.KlammerAuf);
            // Code for NonTerminal specified on line 138 of NewAwkParser.jjt
            pushOntoCallStack("methodSignature", "NewAwkParser.jjt", 138, 67);
            try {
                parameterList();
            }
            finally {
                popCallStack();
            }
            // Code for RegexpRef specified on line 138 of NewAwkParser.jjt
            consumeToken(TokenType.KlammerZu);
            if (trace_enabled) LOGGER.info("Exiting normally from methodSignature");
        }
        catch(ParseException e) {
            parseException7= e;
            throw e;
        }
        finally {
            if (parseException7== null) {
                restoreCallStack(callStackSize7);
            }
            if (buildTree) {
                if (parseException7== null) {
                    closeNodeScope(methodSignature7, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException7.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 140
    final public void parameterList() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 140 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean parameterList8forced= false;
        ParameterList parameterList8= null;
        if (buildTree) {
            parameterList8= new ParameterList();
            openNodeScope(parameterList8);
        }
        ParseException parseException8= null;
        int callStackSize8= parsingStack.size();
        try {
            // Code for ExpansionChoice specified on line 142 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.DataType) {
                // Code for RegexpRef specified on line 142 of NewAwkParser.jjt
                consumeToken(TokenType.DataType);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.ArrayType) {
                // Code for RegexpRef specified on line 142 of NewAwkParser.jjt
                consumeToken(TokenType.ArrayType);
            }
            else {
                pushOntoCallStack("parameterList", "NewAwkParser.jjt", 142, 6);
                throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_142$column_6, parsingStack);
            }
            // Code for RegexpRef specified on line 142 of NewAwkParser.jjt
            consumeToken(TokenType.Bezeichner);
            // Code for ZeroOrOne specified on line 142 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.COMMA) {
                // Code for RegexpRef specified on line 142 of NewAwkParser.jjt
                consumeToken(TokenType.COMMA);
                // Code for ExpansionChoice specified on line 142 of NewAwkParser.jjt
                if (resetScanAhead(1)&&nextTokenType== TokenType.DataType) {
                    // Code for RegexpRef specified on line 142 of NewAwkParser.jjt
                    consumeToken(TokenType.DataType);
                }
                else if (resetScanAhead(1)&&nextTokenType== TokenType.ArrayType) {
                    // Code for RegexpRef specified on line 142 of NewAwkParser.jjt
                    consumeToken(TokenType.ArrayType);
                }
                else {
                    pushOntoCallStack("parameterList", "NewAwkParser.jjt", 142, 55);
                    throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_142$column_55, parsingStack);
                }
                // Code for RegexpRef specified on line 142 of NewAwkParser.jjt
                consumeToken(TokenType.Bezeichner);
            }
            if (trace_enabled) LOGGER.info("Exiting normally from parameterList");
        }
        catch(ParseException e) {
            parseException8= e;
            throw e;
        }
        finally {
            if (parseException8== null) {
                restoreCallStack(callStackSize8);
            }
            if (buildTree) {
                if (parseException8== null) {
                    closeNodeScope(parameterList8, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException8.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 144
    final public void methodBody() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 144 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean methodBody9forced= false;
        MethodBody methodBody9= null;
        if (buildTree) {
            methodBody9= new MethodBody();
            openNodeScope(methodBody9);
        }
        ParseException parseException9= null;
        int callStackSize9= parsingStack.size();
        try {
            // Code for RegexpRef specified on line 146 of NewAwkParser.jjt
            consumeToken(TokenType.BlockAuf);
            // Code for OneOrMore specified on line 146 of NewAwkParser.jjt
            boolean inFirst1= true;
            do {
                // Code for ExpansionChoice specified on line 146 of NewAwkParser.jjt
                if (resetScanAhead(1)&&nextTokenType== TokenType.Bezeichner) {
                    // Code for NonTerminal specified on line 146 of NewAwkParser.jjt
                    pushOntoCallStack("methodBody", "NewAwkParser.jjt", 146, 17);
                    try {
                        assignment();
                    }
                    finally {
                        popCallStack();
                    }
                }
                else if (resetScanAhead(1)&&nextTokenType== TokenType.DataType) {
                    // Code for NonTerminal specified on line 146 of NewAwkParser.jjt
                    pushOntoCallStack("methodBody", "NewAwkParser.jjt", 146, 32);
                    try {
                        fieldDeclarationAndAssignment();
                    }
                    finally {
                        popCallStack();
                    }
                }
                else if (resetScanAhead(1)&&nextTokenType== TokenType.RETURN) {
                    // Code for NonTerminal specified on line 146 of NewAwkParser.jjt
                    pushOntoCallStack("methodBody", "NewAwkParser.jjt", 146, 66);
                    try {
                        returnStatement();
                    }
                    finally {
                        popCallStack();
                    }
                }
                else if (inFirst1) {
                    pushOntoCallStack("methodBody", "NewAwkParser.jjt", 146, 17);
                    throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_146$column_17, parsingStack);
                }
                else {
                    break;
                }
                inFirst1= false;
            }
            while (true);
            // Code for RegexpRef specified on line 146 of NewAwkParser.jjt
            consumeToken(TokenType.BlockZu);
            if (trace_enabled) LOGGER.info("Exiting normally from methodBody");
        }
        catch(ParseException e) {
            parseException9= e;
            throw e;
        }
        finally {
            if (parseException9== null) {
                restoreCallStack(callStackSize9);
            }
            if (buildTree) {
                if (parseException9== null) {
                    closeNodeScope(methodBody9, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException9.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 148
    final public void returnStatement() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 148 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean returnStatement10forced= false;
        ReturnStatement returnStatement10= null;
        if (buildTree) {
            returnStatement10= new ReturnStatement();
            openNodeScope(returnStatement10);
        }
        ParseException parseException10= null;
        int callStackSize10= parsingStack.size();
        try {
            // Code for RegexpRef specified on line 150 of NewAwkParser.jjt
            consumeToken(TokenType.RETURN);
            // Code for ExpansionChoice specified on line 151 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.Bezeichner) {
                // Code for RegexpRef specified on line 151 of NewAwkParser.jjt
                consumeToken(TokenType.Bezeichner);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.IntegerLiteral) {
                // Code for RegexpRef specified on line 151 of NewAwkParser.jjt
                consumeToken(TokenType.IntegerLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.DoubleLiteral) {
                // Code for RegexpRef specified on line 151 of NewAwkParser.jjt
                consumeToken(TokenType.DoubleLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.CharLiteral) {
                // Code for RegexpRef specified on line 151 of NewAwkParser.jjt
                consumeToken(TokenType.CharLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.BooleanValue) {
                // Code for RegexpRef specified on line 152 of NewAwkParser.jjt
                consumeToken(TokenType.BooleanValue);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.StringLiteral) {
                // Code for RegexpRef specified on line 152 of NewAwkParser.jjt
                consumeToken(TokenType.StringLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.NullLiteral) {
                // Code for RegexpRef specified on line 152 of NewAwkParser.jjt
                consumeToken(TokenType.NullLiteral);
            }
            else {
                pushOntoCallStack("returnStatement", "NewAwkParser.jjt", 151, 6);
                throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_151$column_6, parsingStack);
            }
            // Code for RegexpRef specified on line 153 of NewAwkParser.jjt
            consumeToken(TokenType.SEMICOLON);
            if (trace_enabled) LOGGER.info("Exiting normally from returnStatement");
        }
        catch(ParseException e) {
            parseException10= e;
            throw e;
        }
        finally {
            if (parseException10== null) {
                restoreCallStack(callStackSize10);
            }
            if (buildTree) {
                if (parseException10== null) {
                    closeNodeScope(returnStatement10, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException10.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 155
    final public void comparision() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 155 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean comparision11forced= false;
        Comparision comparision11= null;
        if (buildTree) {
            comparision11= new Comparision();
            openNodeScope(comparision11);
        }
        ParseException parseException11= null;
        int callStackSize11= parsingStack.size();
        try {
            // Code for ExpansionChoice specified on line 158 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.Bezeichner) {
                // Code for RegexpRef specified on line 158 of NewAwkParser.jjt
                consumeToken(TokenType.Bezeichner);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.IntegerLiteral) {
                // Code for RegexpRef specified on line 158 of NewAwkParser.jjt
                consumeToken(TokenType.IntegerLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.DoubleLiteral) {
                // Code for RegexpRef specified on line 158 of NewAwkParser.jjt
                consumeToken(TokenType.DoubleLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.CharLiteral) {
                // Code for RegexpRef specified on line 158 of NewAwkParser.jjt
                consumeToken(TokenType.CharLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.BooleanValue) {
                // Code for RegexpRef specified on line 158 of NewAwkParser.jjt
                consumeToken(TokenType.BooleanValue);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.StringLiteral) {
                // Code for RegexpRef specified on line 158 of NewAwkParser.jjt
                consumeToken(TokenType.StringLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.NullLiteral) {
                // Code for RegexpRef specified on line 158 of NewAwkParser.jjt
                consumeToken(TokenType.NullLiteral);
            }
            else {
                pushOntoCallStack("comparision", "NewAwkParser.jjt", 158, 6);
                throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_158$column_6, parsingStack);
            }
            // Code for ExpansionChoice specified on line 159 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.EQUAL) {
                // Code for RegexpRef specified on line 159 of NewAwkParser.jjt
                consumeToken(TokenType.EQUAL);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.NOT_EQUAL) {
                // Code for RegexpRef specified on line 159 of NewAwkParser.jjt
                consumeToken(TokenType.NOT_EQUAL);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.SMALLER) {
                // Code for RegexpRef specified on line 159 of NewAwkParser.jjt
                consumeToken(TokenType.SMALLER);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.S_OR_EQUAL) {
                // Code for RegexpRef specified on line 159 of NewAwkParser.jjt
                consumeToken(TokenType.S_OR_EQUAL);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.GREATER) {
                // Code for RegexpRef specified on line 159 of NewAwkParser.jjt
                consumeToken(TokenType.GREATER);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.G_OR_EQUAL) {
                // Code for RegexpRef specified on line 159 of NewAwkParser.jjt
                consumeToken(TokenType.G_OR_EQUAL);
            }
            else {
                pushOntoCallStack("comparision", "NewAwkParser.jjt", 159, 6);
                throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_159$column_6, parsingStack);
            }
            // Code for ExpansionChoice specified on line 160 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.Bezeichner) {
                // Code for RegexpRef specified on line 160 of NewAwkParser.jjt
                consumeToken(TokenType.Bezeichner);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.IntegerLiteral) {
                // Code for RegexpRef specified on line 160 of NewAwkParser.jjt
                consumeToken(TokenType.IntegerLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.DoubleLiteral) {
                // Code for RegexpRef specified on line 160 of NewAwkParser.jjt
                consumeToken(TokenType.DoubleLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.CharLiteral) {
                // Code for RegexpRef specified on line 160 of NewAwkParser.jjt
                consumeToken(TokenType.CharLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.BooleanValue) {
                // Code for RegexpRef specified on line 160 of NewAwkParser.jjt
                consumeToken(TokenType.BooleanValue);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.StringLiteral) {
                // Code for RegexpRef specified on line 160 of NewAwkParser.jjt
                consumeToken(TokenType.StringLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.NullLiteral) {
                // Code for RegexpRef specified on line 160 of NewAwkParser.jjt
                consumeToken(TokenType.NullLiteral);
            }
            else {
                pushOntoCallStack("comparision", "NewAwkParser.jjt", 160, 6);
                throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_160$column_6, parsingStack);
            }
            if (trace_enabled) LOGGER.info("Exiting normally from comparision");
        }
        catch(ParseException e) {
            parseException11= e;
            throw e;
        }
        finally {
            if (parseException11== null) {
                restoreCallStack(callStackSize11);
            }
            if (buildTree) {
                if (parseException11== null) {
                    closeNodeScope(comparision11, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException11.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_115$column_7= EnumSet.of(TokenType.DataType, TokenType.ArrayType, TokenType.VOID);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_124$column_6= EnumSet.of(TokenType.CharLiteral, TokenType.NullLiteral, TokenType.BooleanValue, TokenType.IntegerLiteral, TokenType.DoubleLiteral, TokenType.Bezeichner, TokenType.StringLiteral);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_138$column_6= EnumSet.of(TokenType.DataType, TokenType.ArrayType, TokenType.VOID);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_142$column_6= EnumSet.of(TokenType.DataType, TokenType.ArrayType);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_142$column_55= EnumSet.of(TokenType.DataType, TokenType.ArrayType);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_146$column_17= EnumSet.of(TokenType.RETURN, TokenType.DataType, TokenType.Bezeichner);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_151$column_6= EnumSet.of(TokenType.CharLiteral, TokenType.NullLiteral, TokenType.BooleanValue, TokenType.IntegerLiteral, TokenType.DoubleLiteral, TokenType.Bezeichner, TokenType.StringLiteral);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_158$column_6= EnumSet.of(TokenType.CharLiteral, TokenType.NullLiteral, TokenType.BooleanValue, TokenType.IntegerLiteral, TokenType.DoubleLiteral, TokenType.Bezeichner, TokenType.StringLiteral);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_159$column_6= EnumSet.of(TokenType.EQUAL, TokenType.NOT_EQUAL, TokenType.G_OR_EQUAL, TokenType.S_OR_EQUAL, TokenType.GREATER, TokenType.SMALLER);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_160$column_6= EnumSet.of(TokenType.CharLiteral, TokenType.NullLiteral, TokenType.BooleanValue, TokenType.IntegerLiteral, TokenType.DoubleLiteral, TokenType.Bezeichner, TokenType.StringLiteral);
    private final boolean scanToken(TokenType expectedType) {
        if (remainingLookahead<=0) return true;
        if (currentLookaheadToken.getNext()== null) {
            Token nextToken= token_source.getNextToken();
            currentLookaheadToken.setNext(nextToken);
        }
        currentLookaheadToken= currentLookaheadToken.getNext();
        TokenType type= currentLookaheadToken.getType();
        if (type!=expectedType) return false;
        if (remainingLookahead!=Integer.MAX_VALUE) remainingLookahead--;
        if (type== upToTokenType) remainingLookahead= 0;
        return true;
    }

    private final boolean scanToken(EnumSet<TokenType> types) {
        if (remainingLookahead<=0) return true;
        if (currentLookaheadToken.getNext()== null) {
            Token nextToken= token_source.getNextToken();
            currentLookaheadToken.setNext(nextToken);
        }
        currentLookaheadToken= currentLookaheadToken.getNext();
        TokenType type= currentLookaheadToken.getType();
        if (!types.contains(type)) return false;
        if (remainingLookahead!=Integer.MAX_VALUE) remainingLookahead--;
        if (type== upToTokenType) remainingLookahead= 0;
        return true;
    }

    //====================================
    // Lookahead Routines
    //====================================
    private final boolean check$NewAwkParser_jjt$line_115$column_7() {
        if (remainingLookahead<=0) return true;
        pushOntoLookaheadStack("fieldOrMethods", "NewAwkParser.jjt", 115, 12);
        if (!check$fieldDeclarationAndAssignment()) {
            popLookaheadStack();
            return false;
        }
        popLookaheadStack();
        return true;
    }

    private final boolean check$fieldDeclarationAndAssignment() {
        if (remainingLookahead<=0) return true;
        if (!scanToken(TokenType.DataType)) return false;
        pushOntoLookaheadStack("fieldDeclarationAndAssignment", "NewAwkParser.jjt", 119, 16);
        if (!check$assignment()) {
            popLookaheadStack();
            return false;
        }
        popLookaheadStack();
        return true;
    }

    private final boolean check$assignment() {
        if (remainingLookahead<=0) return true;
        if (!scanToken(TokenType.Bezeichner)) return false;
        if (!scanToken(TokenType.Zuweisung)) return false;
        if (!scanToken(first_set$NewAwkParser_jjt$line_124$column_6)) return false;
        if (!scanToken(TokenType.SEMICOLON)) return false;
        return true;
    }

    private boolean trace_enabled= true;
    public void setTracingEnabled(boolean tracingEnabled) {
        trace_enabled= tracingEnabled;
    }

    /**
 * @deprecated Use #setTracingEnabled
 */
    @Deprecated public void enable_tracing() {
        setTracingEnabled(true);
    }

    /**
 * @deprecated Use #setTracingEnabled
 */
    @Deprecated public void disable_tracing() {
        setTracingEnabled(false);
    }

    ArrayList<NonTerminalCall> parsingStack= new ArrayList<> ();
    private ArrayList<NonTerminalCall> lookaheadStack= new ArrayList<> ();
    /**
 * Inner class that represents entering a grammar production
 */
    class NonTerminalCall {
        final String sourceFile;
        final String productionName;
        final int line, column;
        NonTerminalCall(String sourceFile, String productionName, int line, int column) {
            this.sourceFile= sourceFile;
            this.productionName= productionName;
            this.line= line;
            this.column= column;
        }

        StackTraceElement createStackTraceElement() {
            return new StackTraceElement("NewAwkParser", productionName, sourceFile, line);
        }

    }
    private final void pushOntoCallStack(String methodName, String fileName, int line, int column) {
        parsingStack.add(new NonTerminalCall(fileName, methodName, line, column));
    }

    private final void popCallStack() {
        parsingStack.remove(parsingStack.size()-1);
    }

    private final void restoreCallStack(int prevSize) {
        while (parsingStack.size()> prevSize) {
            popCallStack();
        }
    }

    private Iterator<NonTerminalCall> stackIteratorForward() {
        final Iterator<NonTerminalCall> parseStackIterator= parsingStack.iterator();
        final Iterator<NonTerminalCall> lookaheadStackIterator= lookaheadStack.iterator();
        return new Iterator<NonTerminalCall> () {
            public boolean hasNext() {
                return parseStackIterator.hasNext()||lookaheadStackIterator.hasNext();
            }

            public NonTerminalCall next() {
                return parseStackIterator.hasNext()?parseStackIterator.next():
                lookaheadStackIterator.next();
            }

        }
        ;
    }

    private Iterator<NonTerminalCall> stackIteratorBackward() {
        final ListIterator<NonTerminalCall> parseStackIterator= parsingStack.listIterator(parsingStack.size());
        final ListIterator<NonTerminalCall> lookaheadStackIterator= lookaheadStack.listIterator(lookaheadStack.size());
        return new Iterator<NonTerminalCall> () {
            public boolean hasNext() {
                return parseStackIterator.hasPrevious()||lookaheadStackIterator.hasPrevious();
            }

            public NonTerminalCall next() {
                return lookaheadStackIterator.hasPrevious()?lookaheadStackIterator.previous():
                parseStackIterator.previous();
            }

        }
        ;
    }

    private final void pushOntoLookaheadStack(String methodName, String fileName, int line, int column) {
        lookaheadStack.add(new NonTerminalCall(fileName, methodName, line, column));
    }

    private final void popLookaheadStack() {
        lookaheadStack.remove(lookaheadStack.size()-1);
    }

    private final boolean tolerantParsing= false;
    public boolean isParserTolerant() {
        return tolerantParsing;
    }

    public void setParserTolerant(boolean tolerantParsing) {
        if (tolerantParsing) {
            throw new UnsupportedOperationException("This parser was not built with that feature!");
        }
    }

    private Token consumeToken(TokenType expectedType) throws ParseException {
        boolean forced= false;
        InvalidToken invalidToken= null;
        Token oldToken= current_token;
        current_token= current_token.getNext();
        if (current_token== null) {
            current_token= token_source.getNextToken();
        }
        if (current_token.getType()!=expectedType) {
            handleUnexpectedTokenType(expectedType, forced, oldToken);
        }
        else {
            this.lastParsedToken= current_token;
        }
        if (buildTree&&tokensAreNodes) {
            if (invalidToken!=null) {
                pushNode(invalidToken);
            }
            pushNode(current_token);
        }
        if (trace_enabled) LOGGER.info("Consumed token of type "+current_token.getType()+" from "+current_token.getLocation());
        return current_token;
    }

    private void handleUnexpectedTokenType(TokenType expectedType, boolean forced, Token oldToken) throws ParseException {
        throw new ParseException(current_token, EnumSet.of(expectedType), parsingStack);
    }

    private class ParseState {
        Token lastParsed;
        NodeScope nodeScope;
        ParseState() {
            this.lastParsed= NewAwkParser.this.lastParsedToken;
            this.nodeScope= (NodeScope) currentNodeScope.clone();
        }

    }
    private ArrayList<ParseState> parseStateStack= new ArrayList<> ();
    void stashParseState() {
        parseStateStack.add(new ParseState());
    }

    ParseState popParseState() {
        return parseStateStack.remove(parseStateStack.size()-1);
    }

    void restoreStashedParseState() {
        ParseState state= popParseState();
        currentNodeScope= state.nodeScope;
        if (state.lastParsed!=null) {
            //REVISIT
            current_token= lastParsedToken= state.lastParsed;
        }
    }

    private boolean buildTree= true;
    private boolean tokensAreNodes= true;
    private boolean unparsedTokensAreNodes= false;
    public void setUnparsedTokensAreNodes(boolean unparsedTokensAreNodes) {
        this.unparsedTokensAreNodes= unparsedTokensAreNodes;
    }

    public void setTokensAreNodes(boolean tokensAreNodes) {
        this.tokensAreNodes= tokensAreNodes;
    }

    NodeScope currentNodeScope= new NodeScope();
    /** 
	 * Returns the root node of the AST.  It only makes sense to call
	 * this after a successful parse. 
	 */
    public Node rootNode() {
        Node root= currentNodeScope.rootNode();
        recursivelySetInputSource(root, this.token_source.input_stream);
        return root;
    }

    static private void recursivelySetInputSource(Node n, FileLineMap fileLineMap) {
        n.setInputSource(fileLineMap);
        for (Node child : n.children()) {
            //            if (child instanceof Token) {
            //                 ((Token) child).setImage(null);
            //            } 
            recursivelySetInputSource(child, fileLineMap);
        }
    }

    /**
     * push a node onto the top of the node stack
     */
    public void pushNode(Node n) {
        currentNodeScope.add(n);
    }

    /** 
     * Returns the node on the top of the stack, and remove it from the
     * stack.  
     */
    public Node popNode() {
        return currentNodeScope.pop();
    }

    /** 
     * Returns the node currently on the top of the stack. 
     */
    public Node peekNode() {
        return currentNodeScope.peek();
    }

    /**
     * Puts the node on the top of the stack. However, unlike pushNode()
     * it replaces the node that is currently on the top of the stack.
     * This is effectively equivalent to popNode() followed by pushNode(n)
     */
    public void pokeNode(Node n) {
        currentNodeScope.poke(n);
    }

    /** Returns the number of children on the stack in the current node
	 * scope. 
	 */
    public int nodeArity() {
        return currentNodeScope.size();
    }

    public void clearNodeScope() {
        currentNodeScope.clear();
    }

    public void openNodeScope(Node n) {
        Token start= getToken(1);
        n.setBeginLine(start.getBeginLine());
        n.setBeginColumn(start.getBeginColumn());
        n.setInputSource(token_source.input_stream);
        new NodeScope();
        n.open();
        if (trace_enabled) LOGGER.info("Opened node scope for node of type: "+n.getClass().getName());
        if (trace_enabled) LOGGER.info("Scope nesting level is "+currentNodeScope.nestingLevel());
    }

    /* A definite node is constructed from a specified number of
	 * children.  That number of nodes are popped from the stack and
	 * made the children of the definite node.  Then the definite node
	 * is pushed on to the stack.
	 */
    public void closeNodeScope(Node n, int num) {
        n.setEndLine(current_token.getEndLine());
        n.setEndColumn(current_token.getEndColumn());
        if (trace_enabled) LOGGER.info("Closing node scope for node of type: "+n.getClass().getName()+", popping "+num+" nodes off the stack.");
        currentNodeScope.close();
        ArrayList<Node> nodes= new ArrayList<Node> ();
        for (int i= 0; i<num; i++) {
            nodes.add(popNode());
        }
        Collections.reverse(nodes);
        for (Node child : nodes) {
            if (unparsedTokensAreNodes&&(child instanceof Token)) {
                Token token= (Token) child;
                Token specialToken= token;
                while (specialToken!=null) {
                    specialToken= specialToken.getSpecialToken();
                }
                while (specialToken!=null&&specialToken!=token) {
                    n.addChild(specialToken);
                    specialToken= specialToken.getNext();
                }
            }
            n.addChild(child);
        }
        n.close();
        pushNode(n);
    }

    /**
	 * A conditional node is constructed if the condition is true.  All
	 * the nodes that have been pushed since the node was opened are
	 * made children of the conditional node, which is then pushed
	 * on to the stack.  If the condition is false the node is not
	 * constructed and they are left on the stack. 
	 */
    public void closeNodeScope(Node n, boolean condition) {
        n.setEndLine(current_token.getEndLine());
        n.setEndColumn(current_token.getEndColumn());
        if (condition) {
            if (trace_enabled) LOGGER.finer("Closing node scope for node of type: "+n.getClass().getName()+", popping "+nodeArity()+" nodes off the stack.");
            int a= nodeArity();
            currentNodeScope.close();
            ArrayList<Node> nodes= new ArrayList<Node> ();
            while (a--> 0) {
                nodes.add(popNode());
            }
            Collections.reverse(nodes);
            for (Node child : nodes) {
                if (unparsedTokensAreNodes&&(child instanceof Token)) {
                    Token token= (Token) child;
                    Token specialToken= token;
                    while (specialToken.getSpecialToken()!=null) {
                        specialToken= specialToken.getSpecialToken();
                    }
                    while (specialToken!=null&&specialToken!=token) {
                        n.addChild(specialToken);
                        specialToken= specialToken.getNext();
                    }
                }
                n.addChild(child);
            }
            n.close();
            if (trace_enabled) {
                LOGGER.info("Closing node scope for node of type: "+n.getClass().getName()+", leaving "+nodeArity()+" nodes on the stack.");
                LOGGER.info("Nesting level is : "+currentNodeScope.nestingLevel());
            }
            pushNode(n);
            if (trace_enabled) {
                LOGGER.info("Closed node scope for node of type: "+n.getClass().getName()+", there are now "+nodeArity()+" nodes on the stack.");
                LOGGER.info("Nesting level is : "+currentNodeScope.nestingLevel());
            }
        }
        else {
            currentNodeScope.close();
            if (trace_enabled) {
                LOGGER.info("Closed node scope for node of type: "+n.getClass().getName()+", leaving "+nodeArity()+" nodes on the stack.");
                LOGGER.info("Nesting level is : "+currentNodeScope.nestingLevel());
            }
        }
    }

    public boolean getBuildTree() {
        return buildTree;
    }

    public void setBuildTree(boolean buildTree) {
        this.buildTree= buildTree;
    }

    /**
     * Just a kludge so that existing jjtree-based code that uses
     * parser.jjtree.foo can work without change.
     */
    NewAwkParser jjtree= this;
    @SuppressWarnings("serial")
    class NodeScope extends ArrayList<Node>  {
        NodeScope parentScope;
        NodeScope() {
            this.parentScope= NewAwkParser.this.currentNodeScope;
            NewAwkParser.this.currentNodeScope= this;
        }

        boolean isRootScope() {
            return parentScope== null;
        }

        Node rootNode() {
            NodeScope ns= this;
            while (ns.parentScope!=null) {
                ns= ns.parentScope;
            }
            return ns.isEmpty()?null:
            ns.get(0);
        }

        Node peek() {
            return isEmpty()?parentScope.peek():
            get(size()-1);
        }

        Node pop() {
            return isEmpty()?parentScope.pop():
            remove(size()-1);
        }

        void poke(Node n) {
            if (isEmpty()) {
                parentScope.poke(n);
            }
            else {
                set(size()-1, n);
            }
        }

        void close() {
            parentScope.addAll(this);
            NewAwkParser.this.currentNodeScope= parentScope;
        }

        int nestingLevel() {
            int result= 0;
            NodeScope parent= this;
            while (parent.parentScope!=null) {
                result++;
                parent= parent.parentScope;
            }
            return result;
        }

    }
}
