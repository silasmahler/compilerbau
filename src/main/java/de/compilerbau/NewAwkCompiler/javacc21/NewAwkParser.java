/* Generated by: JavaCC 21 Parser Generator. NewAwkParser.java */
package de.compilerbau.NewAwkCompiler.javacc21;

import java.util.*;
import java.util.concurrent.CancellationException;
import java.util.logging.*;
import java.io.*;
import static de.compilerbau.NewAwkCompiler.javacc21.NewAwkConstants.TokenType.*;
import de.compilerbau.NewAwkCompiler.javacc21.Node;
import de.compilerbau.NewAwkCompiler.javacc21.NewAwkParser;
import de.compilerbau.NewAwkCompiler.javacc21.ParseException;
import de.compilerbau.NewAwkCompiler.javacc21.Nodes;
@SuppressWarnings("unused")
public class NewAwkParser implements NewAwkConstants {
    static public ArrayList<Node> roots= new ArrayList<> ();
    public static void main(String[] args) throws ParseException, FileNotFoundException {
        /*File file = new File(".\\src\\main\\java\\de\\compilerbau\\NewAwkCompiler\\NewAwkTest.txt");
     FileInputStream is = new FileInputStream(file);
     NewAwkParser parser = new NewAwkParser(new BufferedInputStream(is));
     parser.program();

     parser.printTokens(testToken);

     }
     private void printTokens(String testToken) {
        System.out.println("Test: " + testToken);
     }*/
        System.err.println("Arguments: "+args.length);
        for (String s : args) {
            System.err.println("Arg: "+s);
        }
        List<File> failures= new ArrayList<File> ();
        List<File> successes= new ArrayList<File> ();
        boolean failureOccurred= false;
        NewAwkParser parser;
        if (args.length== 0) {
            usage();
        }
        List<File> files= new ArrayList<File> ();
        for (String arg : args) {
            File file= new File(arg);
            if (!file.exists()) {
                System.err.println("File "+file+" does not exist.");
                continue;
            }
            addFilesRecursively(files, file);
        }
        long startTime= System.currentTimeMillis();
        for (File file : files) {
            try {
                // A bit screwball, we'll dump the tree if there is only one arg. :-)
                parseFile(file, files.size()>=1);
            }
            catch(Exception e) {
                System.err.println("Error processing file: "+file);
                e.printStackTrace();
                failures.add(file);
                continue;
            }
            System.out.println(file.getName()+" parsed successfully.");
            successes.add(file);
        }
        for (File file : failures) {
            System.out.println("Parse failed on: "+file);
        }
        System.out.println("\nParsed "+successes.size()+" files successfully");
        System.out.println("Failed on "+failures.size()+" files.");
        System.out.println("\nDuration: "+(System.currentTimeMillis()-startTime)+" milliseconds");
    }

    static public void parseFile(File file, boolean dumpTree) throws IOException, ParseException {
        FileReader fr= new FileReader(file);
        NewAwkParser parser= new NewAwkParser(fr);
        parser.setInputSource(file.toString());
        Node root= parser.program();
        // Uncomment the following code if you want all the parsed trees
        //  to remain in memory. This is useful if you want to know how much
        //  memory it takes to parse all the source code in the JDK, for example.
        //  (About 8GB if we're talking about JDK 13)
        //       roots.add(root);
        //       if (roots.size() % 1000 == 0) {
        //            System.out.println("-----------------------------------------------");
        //            System.out.println("Parsed "  +  roots.size() + " files.");
        //            System.out.println("-----------------------------------------------");
        //       }
        if (dumpTree) {
            Nodes.dump(root, "");
        }
    }

    static public void addFilesRecursively(List<File> files, File file) {
        if (file.isDirectory()) {
            for (File f : file.listFiles()) {
                addFilesRecursively(files, f);
            }
        }
        else if (file.getName().endsWith("java")&&!file.getName().endsWith("-info.java")||file.getName().endsWith("txt")&&!file.getName().endsWith("-info.java")) {
            files.add(file);
        }
    }

    static public void usage() {
        System.out.println("Usage: java JParse <sourcefiles or directories>");
        System.out.println("If you just pass it one java source file, it dumps the AST");
        System.exit(-1);
    }

    private static final java.util.logging.Logger LOGGER= Logger.getLogger(NewAwkParser.class.getName());
    static {
        LOGGER.setLevel(Level.FINEST);
    }
    public static void setLogLevel(Level level) {
        LOGGER.setLevel(level);
        Logger.getGlobal().getParent().getHandlers()[0].setLevel(level);
    }

    // The last token successfully "consumed"     
    Token current_token;
    private TokenType nextTokenType;
    private Token currentLookaheadToken;
    private int remainingLookahead;
    private TokenType upToTokenType;
    private EnumSet<TokenType> upToFirstSet;
    private Token lastParsedToken;
    //private Token nextToken; //REVISIT
    //private EnumSet<Token> currentFollowSet;
    private boolean cancelled;
    public void cancel() {
        cancelled= true;
    }

    public boolean isCancelled() {
        return cancelled;
    }

    /** Generated Lexer. */
    public NewAwkLexer token_source;
    public void setInputSource(String inputSource) {
        token_source.setInputSource(inputSource);
    }

    String getInputSource() {
        return token_source.getInputSource();
    }

    //=================================
    // Generated constructors
    //=================================
    public NewAwkParser(String inputSource, CharSequence content) {
        this(new NewAwkLexer(inputSource, content));
    }

    public NewAwkParser(CharSequence content) {
        this("input", content);
    }

    public NewAwkParser(java.io.InputStream stream) {
        this(new InputStreamReader(stream));
    }

    public NewAwkParser(Reader reader) {
        this(new NewAwkLexer(reader));
    }

    /** Constructor with user supplied Lexer. */
    public NewAwkParser(NewAwkLexer lexer) {
        token_source= lexer;
        current_token= new Token();
    }

    final public Token getNextToken() {
        if (current_token.getNext()!=null) current_token= current_token.getNext();
        else {
            Token nextToken= token_source.getNextToken();
            current_token.setNext(nextToken);
            current_token= nextToken;
        }
        return current_token;
    }

    /** Get the specific Token index ahead in the stream. */
    final public Token getToken(int index) {
        Token t= current_token;
        for (int i= 0; i<index; i++) {
            if (t.getNext()!=null) t= t.getNext();
            else {
                Token nextToken= token_source.getNextToken();
                t.setNext(nextToken);
                t= nextToken;
            }
        }
        return t;
    }

    private final boolean setNextTokenType() {
        if (current_token.getNext()== null) {
            Token nextToken= token_source.getNextToken();
            current_token.setNext(nextToken);
        }
        nextTokenType= current_token.getNext().getType();
        return true;
    }

    private final TokenType nextTokenType() {
        setNextTokenType();
        return nextTokenType;
    }

    private final boolean resetScanAhead(int amount, EnumSet<TokenType> upToFirstSet) {
        resetScanAhead(amount);
        this.upToFirstSet= upToFirstSet;
        return true;
    }

    private final boolean resetScanAhead(int amount, TokenType upToTokenType) {
        resetScanAhead(amount);
        this.upToTokenType= upToTokenType;
        return true;
    }

    private final boolean resetScanAhead(int amount) {
        currentLookaheadToken= current_token;
        remainingLookahead= amount;
        this.upToTokenType= null;
        this.upToFirstSet= null;
        setNextTokenType();
        return true;
    }

    /*
    ==============================================================================================
    Parser Rules and AST generation are defined/handled in this section
    ==============================================================================================
*/
    // NewAwkParser.jjt, line 198
    final public Node program() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 198 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean program1forced= false;
        Program program1= null;
        if (buildTree) {
            program1= new Program();
            openNodeScope(program1);
        }
        ParseException parseException1= null;
        int callStackSize1= parsingStack.size();
        try {
            Token t;
            // Code for NonTerminal specified on line 202 of NewAwkParser.jjt
            pushOntoCallStack("program", "NewAwkParser.jjt", 202, 5);
            try {
                fieldOrMethods();
            }
            finally {
                popCallStack();
            }
            // Code for EndOfFile specified on line 203 of NewAwkParser.jjt
            consumeToken(TokenType.EOF);
            // Code for CodeBlock specified on line 204 of NewAwkParser.jjt
            return program1;
        }
        catch(ParseException e) {
            parseException1= e;
            throw e;
        }
        finally {
            if (parseException1== null) {
                restoreCallStack(callStackSize1);
            }
            if (buildTree) {
                if (parseException1== null) {
                    closeNodeScope(program1, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException1.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 206
    final public void fieldOrMethods() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 206 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean fieldOrMethods2forced= false;
        FieldOrMethods fieldOrMethods2= null;
        if (buildTree) {
            fieldOrMethods2= new FieldOrMethods();
            openNodeScope(fieldOrMethods2);
        }
        ParseException parseException2= null;
        int callStackSize2= parsingStack.size();
        try {
            // Code for OneOrMore specified on line 208 of NewAwkParser.jjt
            boolean inFirst0= true;
            do {
                // Code for ExpansionChoice specified on line 208 of NewAwkParser.jjt
                if (resetScanAhead(2147483647)&&check$NewAwkParser_jjt$line_208$column_7()) {
                    // Code for NonTerminal specified on line 208 of NewAwkParser.jjt
                    pushOntoCallStack("fieldOrMethods", "NewAwkParser.jjt", 208, 12);
                    try {
                        fieldDeclarationAndAssignment();
                    }
                    finally {
                        popCallStack();
                    }
                }
                else if (resetScanAhead(1)&&nextTokenType== TokenType.VOID||nextTokenType== TokenType.DataType||nextTokenType== TokenType.ArrayType) {
                    // Code for NonTerminal specified on line 208 of NewAwkParser.jjt
                    pushOntoCallStack("fieldOrMethods", "NewAwkParser.jjt", 208, 46);
                    try {
                        methodDeclaration();
                    }
                    finally {
                        popCallStack();
                    }
                }
                else if (inFirst0) {
                    pushOntoCallStack("fieldOrMethods", "NewAwkParser.jjt", 208, 7);
                    throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_208$column_7, parsingStack);
                }
                else {
                    break;
                }
                inFirst0= false;
            }
            while (true);
            if (trace_enabled) LOGGER.info("Exiting normally from fieldOrMethods");
        }
        catch(ParseException e) {
            parseException2= e;
            throw e;
        }
        finally {
            if (parseException2== null) {
                restoreCallStack(callStackSize2);
            }
            if (buildTree) {
                if (parseException2== null) {
                    closeNodeScope(fieldOrMethods2, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException2.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 210
    final public void fieldDeclarationAndAssignment() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 210 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean fieldDeclarationAndAssignment3forced= false;
        FieldDeclarationAndAssignment fieldDeclarationAndAssignment3= null;
        if (buildTree) {
            fieldDeclarationAndAssignment3= new FieldDeclarationAndAssignment();
            openNodeScope(fieldDeclarationAndAssignment3);
        }
        ParseException parseException3= null;
        int callStackSize3= parsingStack.size();
        try {
            // Code for RegexpRef specified on line 212 of NewAwkParser.jjt
            consumeToken(TokenType.DataType);
            // Code for NonTerminal specified on line 212 of NewAwkParser.jjt
            pushOntoCallStack("fieldDeclarationAndAssignment", "NewAwkParser.jjt", 212, 16);
            try {
                assignment();
            }
            finally {
                popCallStack();
            }
            if (trace_enabled) LOGGER.info("Exiting normally from fieldDeclarationAndAssignment");
        }
        catch(ParseException e) {
            parseException3= e;
            throw e;
        }
        finally {
            if (parseException3== null) {
                restoreCallStack(callStackSize3);
            }
            if (buildTree) {
                if (parseException3== null) {
                    closeNodeScope(fieldDeclarationAndAssignment3, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException3.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 214
    final public void assignment() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 214 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean assignment4forced= false;
        Assignment assignment4= null;
        if (buildTree) {
            assignment4= new Assignment();
            openNodeScope(assignment4);
        }
        ParseException parseException4= null;
        int callStackSize4= parsingStack.size();
        try {
            // Code for RegexpRef specified on line 216 of NewAwkParser.jjt
            consumeToken(TokenType.Bezeichner);
            // Code for RegexpRef specified on line 216 of NewAwkParser.jjt
            consumeToken(TokenType.Zuweisung);
            // Code for ExpansionChoice specified on line 217 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.Bezeichner) {
                // Code for RegexpRef specified on line 217 of NewAwkParser.jjt
                consumeToken(TokenType.Bezeichner);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.IntegerLiteral) {
                // Code for RegexpRef specified on line 217 of NewAwkParser.jjt
                consumeToken(TokenType.IntegerLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.DoubleLiteral) {
                // Code for RegexpRef specified on line 217 of NewAwkParser.jjt
                consumeToken(TokenType.DoubleLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.CharLiteral) {
                // Code for RegexpRef specified on line 217 of NewAwkParser.jjt
                consumeToken(TokenType.CharLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.BooleanValue) {
                // Code for RegexpRef specified on line 217 of NewAwkParser.jjt
                consumeToken(TokenType.BooleanValue);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.StringLiteral) {
                // Code for RegexpRef specified on line 217 of NewAwkParser.jjt
                consumeToken(TokenType.StringLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.NullLiteral) {
                // Code for RegexpRef specified on line 217 of NewAwkParser.jjt
                consumeToken(TokenType.NullLiteral);
            }
            else {
                pushOntoCallStack("assignment", "NewAwkParser.jjt", 217, 6);
                throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_217$column_6, parsingStack);
            }
            // Code for RegexpRef specified on line 218 of NewAwkParser.jjt
            consumeToken(TokenType.SEMICOLON);
            if (trace_enabled) LOGGER.info("Exiting normally from assignment");
        }
        catch(ParseException e) {
            parseException4= e;
            throw e;
        }
        finally {
            if (parseException4== null) {
                restoreCallStack(callStackSize4);
            }
            if (buildTree) {
                if (parseException4== null) {
                    closeNodeScope(assignment4, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException4.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 220
    final public void arrayAssignment() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 220 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean arrayAssignment5forced= false;
        ArrayAssignment arrayAssignment5= null;
        if (buildTree) {
            arrayAssignment5= new ArrayAssignment();
            openNodeScope(arrayAssignment5);
        }
        ParseException parseException5= null;
        int callStackSize5= parsingStack.size();
        try {
            // Code for RegexpRef specified on line 222 of NewAwkParser.jjt
            consumeToken(TokenType.ArrayType);
            // Code for NonTerminal specified on line 222 of NewAwkParser.jjt
            pushOntoCallStack("arrayAssignment", "NewAwkParser.jjt", 222, 17);
            try {
                assignment();
            }
            finally {
                popCallStack();
            }
            if (trace_enabled) LOGGER.info("Exiting normally from arrayAssignment");
        }
        catch(ParseException e) {
            parseException5= e;
            throw e;
        }
        finally {
            if (parseException5== null) {
                restoreCallStack(callStackSize5);
            }
            if (buildTree) {
                if (parseException5== null) {
                    closeNodeScope(arrayAssignment5, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException5.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 224
    final public void methodDeclaration() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 224 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean methodDeclaration6forced= false;
        Method methodDeclaration6= null;
        if (buildTree) {
            methodDeclaration6= new Method();
            openNodeScope(methodDeclaration6);
        }
        ParseException parseException6= null;
        int callStackSize6= parsingStack.size();
        try {
            // Code for NonTerminal specified on line 226 of NewAwkParser.jjt
            pushOntoCallStack("methodDeclaration", "NewAwkParser.jjt", 226, 5);
            try {
                methodSignature();
            }
            finally {
                popCallStack();
            }
            // Code for NonTerminal specified on line 227 of NewAwkParser.jjt
            pushOntoCallStack("methodDeclaration", "NewAwkParser.jjt", 227, 5);
            try {
                methodBody();
            }
            finally {
                popCallStack();
            }
            if (trace_enabled) LOGGER.info("Exiting normally from methodDeclaration");
        }
        catch(ParseException e) {
            parseException6= e;
            throw e;
        }
        finally {
            if (parseException6== null) {
                restoreCallStack(callStackSize6);
            }
            if (buildTree) {
                if (parseException6== null) {
                    closeNodeScope(methodDeclaration6, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException6.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 229
    final public void methodSignature() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 229 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean methodSignature7forced= false;
        MethodSignature methodSignature7= null;
        if (buildTree) {
            methodSignature7= new MethodSignature();
            openNodeScope(methodSignature7);
        }
        ParseException parseException7= null;
        int callStackSize7= parsingStack.size();
        try {
            // Code for ExpansionChoice specified on line 231 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.DataType) {
                // Code for RegexpRef specified on line 231 of NewAwkParser.jjt
                consumeToken(TokenType.DataType);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.ArrayType) {
                // Code for RegexpRef specified on line 231 of NewAwkParser.jjt
                consumeToken(TokenType.ArrayType);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.VOID) {
                // Code for RegexpRef specified on line 231 of NewAwkParser.jjt
                consumeToken(TokenType.VOID);
            }
            else {
                pushOntoCallStack("methodSignature", "NewAwkParser.jjt", 231, 6);
                throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_231$column_6, parsingStack);
            }
            // Code for RegexpRef specified on line 231 of NewAwkParser.jjt
            consumeToken(TokenType.Bezeichner);
            // Code for RegexpRef specified on line 231 of NewAwkParser.jjt
            consumeToken(TokenType.KlammerAuf);
            // Code for NonTerminal specified on line 231 of NewAwkParser.jjt
            pushOntoCallStack("methodSignature", "NewAwkParser.jjt", 231, 67);
            try {
                parameterList();
            }
            finally {
                popCallStack();
            }
            // Code for RegexpRef specified on line 231 of NewAwkParser.jjt
            consumeToken(TokenType.KlammerZu);
            if (trace_enabled) LOGGER.info("Exiting normally from methodSignature");
        }
        catch(ParseException e) {
            parseException7= e;
            throw e;
        }
        finally {
            if (parseException7== null) {
                restoreCallStack(callStackSize7);
            }
            if (buildTree) {
                if (parseException7== null) {
                    closeNodeScope(methodSignature7, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException7.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 233
    final public void parameterList() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 233 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean parameterList8forced= false;
        ParameterList parameterList8= null;
        if (buildTree) {
            parameterList8= new ParameterList();
            openNodeScope(parameterList8);
        }
        ParseException parseException8= null;
        int callStackSize8= parsingStack.size();
        try {
            // Code for ExpansionChoice specified on line 235 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.DataType) {
                // Code for RegexpRef specified on line 235 of NewAwkParser.jjt
                consumeToken(TokenType.DataType);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.ArrayType) {
                // Code for RegexpRef specified on line 235 of NewAwkParser.jjt
                consumeToken(TokenType.ArrayType);
            }
            else {
                pushOntoCallStack("parameterList", "NewAwkParser.jjt", 235, 6);
                throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_235$column_6, parsingStack);
            }
            // Code for RegexpRef specified on line 235 of NewAwkParser.jjt
            consumeToken(TokenType.Bezeichner);
            // Code for ZeroOrOne specified on line 235 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.COMMA) {
                // Code for RegexpRef specified on line 235 of NewAwkParser.jjt
                consumeToken(TokenType.COMMA);
                // Code for ExpansionChoice specified on line 235 of NewAwkParser.jjt
                if (resetScanAhead(1)&&nextTokenType== TokenType.DataType) {
                    // Code for RegexpRef specified on line 235 of NewAwkParser.jjt
                    consumeToken(TokenType.DataType);
                }
                else if (resetScanAhead(1)&&nextTokenType== TokenType.ArrayType) {
                    // Code for RegexpRef specified on line 235 of NewAwkParser.jjt
                    consumeToken(TokenType.ArrayType);
                }
                else {
                    pushOntoCallStack("parameterList", "NewAwkParser.jjt", 235, 55);
                    throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_235$column_55, parsingStack);
                }
                // Code for RegexpRef specified on line 235 of NewAwkParser.jjt
                consumeToken(TokenType.Bezeichner);
            }
            if (trace_enabled) LOGGER.info("Exiting normally from parameterList");
        }
        catch(ParseException e) {
            parseException8= e;
            throw e;
        }
        finally {
            if (parseException8== null) {
                restoreCallStack(callStackSize8);
            }
            if (buildTree) {
                if (parseException8== null) {
                    closeNodeScope(parameterList8, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException8.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 237
    final public void methodBody() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 237 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean methodBody9forced= false;
        MethodBody methodBody9= null;
        if (buildTree) {
            methodBody9= new MethodBody();
            openNodeScope(methodBody9);
        }
        ParseException parseException9= null;
        int callStackSize9= parsingStack.size();
        try {
            // Code for RegexpRef specified on line 239 of NewAwkParser.jjt
            consumeToken(TokenType.BlockAuf);
            // Code for OneOrMore specified on line 239 of NewAwkParser.jjt
            boolean inFirst1= true;
            do {
                // Code for ExpansionChoice specified on line 239 of NewAwkParser.jjt
                if (resetScanAhead(1)&&nextTokenType== TokenType.Bezeichner) {
                    // Code for NonTerminal specified on line 239 of NewAwkParser.jjt
                    pushOntoCallStack("methodBody", "NewAwkParser.jjt", 239, 17);
                    try {
                        assignment();
                    }
                    finally {
                        popCallStack();
                    }
                }
                else if (resetScanAhead(1)&&nextTokenType== TokenType.DataType) {
                    // Code for NonTerminal specified on line 239 of NewAwkParser.jjt
                    pushOntoCallStack("methodBody", "NewAwkParser.jjt", 239, 32);
                    try {
                        fieldDeclarationAndAssignment();
                    }
                    finally {
                        popCallStack();
                    }
                }
                else if (resetScanAhead(1)&&nextTokenType== TokenType.RETURN) {
                    // Code for NonTerminal specified on line 239 of NewAwkParser.jjt
                    pushOntoCallStack("methodBody", "NewAwkParser.jjt", 239, 66);
                    try {
                        returnStatement();
                    }
                    finally {
                        popCallStack();
                    }
                }
                else if (inFirst1) {
                    pushOntoCallStack("methodBody", "NewAwkParser.jjt", 239, 17);
                    throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_239$column_17, parsingStack);
                }
                else {
                    break;
                }
                inFirst1= false;
            }
            while (true);
            // Code for RegexpRef specified on line 239 of NewAwkParser.jjt
            consumeToken(TokenType.BlockZu);
            if (trace_enabled) LOGGER.info("Exiting normally from methodBody");
        }
        catch(ParseException e) {
            parseException9= e;
            throw e;
        }
        finally {
            if (parseException9== null) {
                restoreCallStack(callStackSize9);
            }
            if (buildTree) {
                if (parseException9== null) {
                    closeNodeScope(methodBody9, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException9.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 241
    final public void returnStatement() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 241 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean returnStatement10forced= false;
        ReturnStatement returnStatement10= null;
        if (buildTree) {
            returnStatement10= new ReturnStatement();
            openNodeScope(returnStatement10);
        }
        ParseException parseException10= null;
        int callStackSize10= parsingStack.size();
        try {
            // Code for RegexpRef specified on line 243 of NewAwkParser.jjt
            consumeToken(TokenType.RETURN);
            // Code for ExpansionChoice specified on line 244 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.Bezeichner) {
                // Code for RegexpRef specified on line 244 of NewAwkParser.jjt
                consumeToken(TokenType.Bezeichner);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.IntegerLiteral) {
                // Code for RegexpRef specified on line 244 of NewAwkParser.jjt
                consumeToken(TokenType.IntegerLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.DoubleLiteral) {
                // Code for RegexpRef specified on line 244 of NewAwkParser.jjt
                consumeToken(TokenType.DoubleLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.CharLiteral) {
                // Code for RegexpRef specified on line 244 of NewAwkParser.jjt
                consumeToken(TokenType.CharLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.BooleanValue) {
                // Code for RegexpRef specified on line 245 of NewAwkParser.jjt
                consumeToken(TokenType.BooleanValue);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.StringLiteral) {
                // Code for RegexpRef specified on line 245 of NewAwkParser.jjt
                consumeToken(TokenType.StringLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.NullLiteral) {
                // Code for RegexpRef specified on line 245 of NewAwkParser.jjt
                consumeToken(TokenType.NullLiteral);
            }
            else {
                pushOntoCallStack("returnStatement", "NewAwkParser.jjt", 244, 6);
                throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_244$column_6, parsingStack);
            }
            // Code for RegexpRef specified on line 246 of NewAwkParser.jjt
            consumeToken(TokenType.SEMICOLON);
            if (trace_enabled) LOGGER.info("Exiting normally from returnStatement");
        }
        catch(ParseException e) {
            parseException10= e;
            throw e;
        }
        finally {
            if (parseException10== null) {
                restoreCallStack(callStackSize10);
            }
            if (buildTree) {
                if (parseException10== null) {
                    closeNodeScope(returnStatement10, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException10.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    // NewAwkParser.jjt, line 248
    final public void comparision() throws ParseException {
        if (trace_enabled) LOGGER.info("Entering production defined on line 248 of NewAwkParser.jjt");
        if (cancelled) throw new CancellationException();
        boolean comparision11forced= false;
        Comparision comparision11= null;
        if (buildTree) {
            comparision11= new Comparision();
            openNodeScope(comparision11);
        }
        ParseException parseException11= null;
        int callStackSize11= parsingStack.size();
        try {
            // Code for ExpansionChoice specified on line 251 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.Bezeichner) {
                // Code for RegexpRef specified on line 251 of NewAwkParser.jjt
                consumeToken(TokenType.Bezeichner);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.IntegerLiteral) {
                // Code for RegexpRef specified on line 251 of NewAwkParser.jjt
                consumeToken(TokenType.IntegerLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.DoubleLiteral) {
                // Code for RegexpRef specified on line 251 of NewAwkParser.jjt
                consumeToken(TokenType.DoubleLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.CharLiteral) {
                // Code for RegexpRef specified on line 251 of NewAwkParser.jjt
                consumeToken(TokenType.CharLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.BooleanValue) {
                // Code for RegexpRef specified on line 251 of NewAwkParser.jjt
                consumeToken(TokenType.BooleanValue);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.StringLiteral) {
                // Code for RegexpRef specified on line 251 of NewAwkParser.jjt
                consumeToken(TokenType.StringLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.NullLiteral) {
                // Code for RegexpRef specified on line 251 of NewAwkParser.jjt
                consumeToken(TokenType.NullLiteral);
            }
            else {
                pushOntoCallStack("comparision", "NewAwkParser.jjt", 251, 6);
                throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_251$column_6, parsingStack);
            }
            // Code for ExpansionChoice specified on line 252 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.EQUAL) {
                // Code for RegexpRef specified on line 252 of NewAwkParser.jjt
                consumeToken(TokenType.EQUAL);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.NOT_EQUAL) {
                // Code for RegexpRef specified on line 252 of NewAwkParser.jjt
                consumeToken(TokenType.NOT_EQUAL);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.SMALLER) {
                // Code for RegexpRef specified on line 252 of NewAwkParser.jjt
                consumeToken(TokenType.SMALLER);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.S_OR_EQUAL) {
                // Code for RegexpRef specified on line 252 of NewAwkParser.jjt
                consumeToken(TokenType.S_OR_EQUAL);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.GREATER) {
                // Code for RegexpRef specified on line 252 of NewAwkParser.jjt
                consumeToken(TokenType.GREATER);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.G_OR_EQUAL) {
                // Code for RegexpRef specified on line 252 of NewAwkParser.jjt
                consumeToken(TokenType.G_OR_EQUAL);
            }
            else {
                pushOntoCallStack("comparision", "NewAwkParser.jjt", 252, 6);
                throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_252$column_6, parsingStack);
            }
            // Code for ExpansionChoice specified on line 253 of NewAwkParser.jjt
            if (resetScanAhead(1)&&nextTokenType== TokenType.Bezeichner) {
                // Code for RegexpRef specified on line 253 of NewAwkParser.jjt
                consumeToken(TokenType.Bezeichner);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.IntegerLiteral) {
                // Code for RegexpRef specified on line 253 of NewAwkParser.jjt
                consumeToken(TokenType.IntegerLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.DoubleLiteral) {
                // Code for RegexpRef specified on line 253 of NewAwkParser.jjt
                consumeToken(TokenType.DoubleLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.CharLiteral) {
                // Code for RegexpRef specified on line 253 of NewAwkParser.jjt
                consumeToken(TokenType.CharLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.BooleanValue) {
                // Code for RegexpRef specified on line 253 of NewAwkParser.jjt
                consumeToken(TokenType.BooleanValue);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.StringLiteral) {
                // Code for RegexpRef specified on line 253 of NewAwkParser.jjt
                consumeToken(TokenType.StringLiteral);
            }
            else if (resetScanAhead(1)&&nextTokenType== TokenType.NullLiteral) {
                // Code for RegexpRef specified on line 253 of NewAwkParser.jjt
                consumeToken(TokenType.NullLiteral);
            }
            else {
                pushOntoCallStack("comparision", "NewAwkParser.jjt", 253, 6);
                throw new ParseException(current_token.getNext(), first_set$NewAwkParser_jjt$line_253$column_6, parsingStack);
            }
            if (trace_enabled) LOGGER.info("Exiting normally from comparision");
        }
        catch(ParseException e) {
            parseException11= e;
            throw e;
        }
        finally {
            if (parseException11== null) {
                restoreCallStack(callStackSize11);
            }
            if (buildTree) {
                if (parseException11== null) {
                    closeNodeScope(comparision11, true);
                }
                else {
                    if (trace_enabled) LOGGER.warning("ParseException: "+parseException11.getMessage());
                    clearNodeScope();
                }
            }
        }
    }

    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_208$column_7= EnumSet.of(TokenType.VOID, TokenType.DataType, TokenType.ArrayType);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_217$column_6= EnumSet.of(TokenType.NullLiteral, TokenType.CharLiteral, TokenType.BooleanValue, TokenType.IntegerLiteral, TokenType.DoubleLiteral, TokenType.Bezeichner, TokenType.StringLiteral);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_231$column_6= EnumSet.of(TokenType.VOID, TokenType.DataType, TokenType.ArrayType);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_235$column_6= EnumSet.of(TokenType.DataType, TokenType.ArrayType);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_235$column_55= EnumSet.of(TokenType.DataType, TokenType.ArrayType);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_239$column_17= EnumSet.of(TokenType.RETURN, TokenType.DataType, TokenType.Bezeichner);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_244$column_6= EnumSet.of(TokenType.NullLiteral, TokenType.CharLiteral, TokenType.BooleanValue, TokenType.IntegerLiteral, TokenType.DoubleLiteral, TokenType.Bezeichner, TokenType.StringLiteral);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_251$column_6= EnumSet.of(TokenType.NullLiteral, TokenType.CharLiteral, TokenType.BooleanValue, TokenType.IntegerLiteral, TokenType.DoubleLiteral, TokenType.Bezeichner, TokenType.StringLiteral);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_252$column_6= EnumSet.of(TokenType.EQUAL, TokenType.NOT_EQUAL, TokenType.G_OR_EQUAL, TokenType.S_OR_EQUAL, TokenType.GREATER, TokenType.SMALLER);
    static private final EnumSet<TokenType> first_set$NewAwkParser_jjt$line_253$column_6= EnumSet.of(TokenType.NullLiteral, TokenType.CharLiteral, TokenType.BooleanValue, TokenType.IntegerLiteral, TokenType.DoubleLiteral, TokenType.Bezeichner, TokenType.StringLiteral);
    private final boolean scanToken(TokenType expectedType) {
        if (remainingLookahead<=0) return true;
        if (currentLookaheadToken.getNext()== null) {
            Token nextToken= token_source.getNextToken();
            currentLookaheadToken.setNext(nextToken);
        }
        currentLookaheadToken= currentLookaheadToken.getNext();
        TokenType type= currentLookaheadToken.getType();
        if (type!=expectedType) return false;
        if (remainingLookahead!=Integer.MAX_VALUE) remainingLookahead--;
        if (type== upToTokenType) remainingLookahead= 0;
        return true;
    }

    private final boolean scanToken(EnumSet<TokenType> types) {
        if (remainingLookahead<=0) return true;
        if (currentLookaheadToken.getNext()== null) {
            Token nextToken= token_source.getNextToken();
            currentLookaheadToken.setNext(nextToken);
        }
        currentLookaheadToken= currentLookaheadToken.getNext();
        TokenType type= currentLookaheadToken.getType();
        if (!types.contains(type)) return false;
        if (remainingLookahead!=Integer.MAX_VALUE) remainingLookahead--;
        if (type== upToTokenType) remainingLookahead= 0;
        return true;
    }

    //====================================
    // Lookahead Routines
    //====================================
    private final boolean check$NewAwkParser_jjt$line_208$column_7() {
        if (remainingLookahead<=0) return true;
        pushOntoLookaheadStack("fieldOrMethods", "NewAwkParser.jjt", 208, 12);
        if (!check$fieldDeclarationAndAssignment()) {
            popLookaheadStack();
            return false;
        }
        popLookaheadStack();
        return true;
    }

    private final boolean check$fieldDeclarationAndAssignment() {
        if (remainingLookahead<=0) return true;
        if (!scanToken(TokenType.DataType)) return false;
        pushOntoLookaheadStack("fieldDeclarationAndAssignment", "NewAwkParser.jjt", 212, 16);
        if (!check$assignment()) {
            popLookaheadStack();
            return false;
        }
        popLookaheadStack();
        return true;
    }

    private final boolean check$assignment() {
        if (remainingLookahead<=0) return true;
        if (!scanToken(TokenType.Bezeichner)) return false;
        if (!scanToken(TokenType.Zuweisung)) return false;
        if (!scanToken(first_set$NewAwkParser_jjt$line_217$column_6)) return false;
        if (!scanToken(TokenType.SEMICOLON)) return false;
        return true;
    }

    private boolean trace_enabled= true;
    public void setTracingEnabled(boolean tracingEnabled) {
        trace_enabled= tracingEnabled;
    }

    /**
 * @deprecated Use #setTracingEnabled
 */
    @Deprecated public void enable_tracing() {
        setTracingEnabled(true);
    }

    /**
 * @deprecated Use #setTracingEnabled
 */
    @Deprecated public void disable_tracing() {
        setTracingEnabled(false);
    }

    ArrayList<NonTerminalCall> parsingStack= new ArrayList<> ();
    private ArrayList<NonTerminalCall> lookaheadStack= new ArrayList<> ();
    /**
 * Inner class that represents entering a grammar production
 */
    class NonTerminalCall {
        final String sourceFile;
        final String productionName;
        final int line, column;
        NonTerminalCall(String sourceFile, String productionName, int line, int column) {
            this.sourceFile= sourceFile;
            this.productionName= productionName;
            this.line= line;
            this.column= column;
        }

        StackTraceElement createStackTraceElement() {
            return new StackTraceElement("NewAwkParser", productionName, sourceFile, line);
        }

    }
    private final void pushOntoCallStack(String methodName, String fileName, int line, int column) {
        parsingStack.add(new NonTerminalCall(fileName, methodName, line, column));
    }

    private final void popCallStack() {
        parsingStack.remove(parsingStack.size()-1);
    }

    private final void restoreCallStack(int prevSize) {
        while (parsingStack.size()> prevSize) {
            popCallStack();
        }
    }

    private Iterator<NonTerminalCall> stackIteratorForward() {
        final Iterator<NonTerminalCall> parseStackIterator= parsingStack.iterator();
        final Iterator<NonTerminalCall> lookaheadStackIterator= lookaheadStack.iterator();
        return new Iterator<NonTerminalCall> () {
            public boolean hasNext() {
                return parseStackIterator.hasNext()||lookaheadStackIterator.hasNext();
            }

            public NonTerminalCall next() {
                return parseStackIterator.hasNext()?parseStackIterator.next():
                lookaheadStackIterator.next();
            }

        }
        ;
    }

    private Iterator<NonTerminalCall> stackIteratorBackward() {
        final ListIterator<NonTerminalCall> parseStackIterator= parsingStack.listIterator(parsingStack.size());
        final ListIterator<NonTerminalCall> lookaheadStackIterator= lookaheadStack.listIterator(lookaheadStack.size());
        return new Iterator<NonTerminalCall> () {
            public boolean hasNext() {
                return parseStackIterator.hasPrevious()||lookaheadStackIterator.hasPrevious();
            }

            public NonTerminalCall next() {
                return lookaheadStackIterator.hasPrevious()?lookaheadStackIterator.previous():
                parseStackIterator.previous();
            }

        }
        ;
    }

    private final void pushOntoLookaheadStack(String methodName, String fileName, int line, int column) {
        lookaheadStack.add(new NonTerminalCall(fileName, methodName, line, column));
    }

    private final void popLookaheadStack() {
        lookaheadStack.remove(lookaheadStack.size()-1);
    }

    private final boolean tolerantParsing= false;
    public boolean isParserTolerant() {
        return tolerantParsing;
    }

    public void setParserTolerant(boolean tolerantParsing) {
        if (tolerantParsing) {
            throw new UnsupportedOperationException("This parser was not built with that feature!");
        }
    }

    private Token consumeToken(TokenType expectedType) throws ParseException {
        boolean forced= false;
        InvalidToken invalidToken= null;
        Token oldToken= current_token;
        current_token= current_token.getNext();
        if (current_token== null) {
            current_token= token_source.getNextToken();
        }
        if (current_token.getType()!=expectedType) {
            handleUnexpectedTokenType(expectedType, forced, oldToken);
        }
        else {
            this.lastParsedToken= current_token;
        }
        if (buildTree&&tokensAreNodes) {
            if (invalidToken!=null) {
                pushNode(invalidToken);
            }
            pushNode(current_token);
        }
        if (trace_enabled) LOGGER.info("Consumed token of type "+current_token.getType()+" from "+current_token.getLocation());
        return current_token;
    }

    private void handleUnexpectedTokenType(TokenType expectedType, boolean forced, Token oldToken) throws ParseException {
        throw new ParseException(current_token, EnumSet.of(expectedType), parsingStack);
    }

    private class ParseState {
        Token lastParsed;
        NodeScope nodeScope;
        ParseState() {
            this.lastParsed= NewAwkParser.this.lastParsedToken;
            this.nodeScope= (NodeScope) currentNodeScope.clone();
        }

    }
    private ArrayList<ParseState> parseStateStack= new ArrayList<> ();
    void stashParseState() {
        parseStateStack.add(new ParseState());
    }

    ParseState popParseState() {
        return parseStateStack.remove(parseStateStack.size()-1);
    }

    void restoreStashedParseState() {
        ParseState state= popParseState();
        currentNodeScope= state.nodeScope;
        if (state.lastParsed!=null) {
            //REVISIT
            current_token= lastParsedToken= state.lastParsed;
        }
    }

    private boolean buildTree= true;
    private boolean tokensAreNodes= true;
    private boolean unparsedTokensAreNodes= false;
    public void setUnparsedTokensAreNodes(boolean unparsedTokensAreNodes) {
        this.unparsedTokensAreNodes= unparsedTokensAreNodes;
    }

    public void setTokensAreNodes(boolean tokensAreNodes) {
        this.tokensAreNodes= tokensAreNodes;
    }

    NodeScope currentNodeScope= new NodeScope();
    /** 
	 * Returns the root node of the AST.  It only makes sense to call
	 * this after a successful parse. 
	 */
    public Node rootNode() {
        Node root= currentNodeScope.rootNode();
        recursivelySetInputSource(root, this.token_source.input_stream);
        return root;
    }

    static private void recursivelySetInputSource(Node n, FileLineMap fileLineMap) {
        n.setInputSource(fileLineMap);
        for (Node child : n.children()) {
            //            if (child instanceof Token) {
            //                 ((Token) child).setImage(null);
            //            } 
            recursivelySetInputSource(child, fileLineMap);
        }
    }

    /**
     * push a node onto the top of the node stack
     */
    public void pushNode(Node n) {
        currentNodeScope.add(n);
    }

    /** 
     * Returns the node on the top of the stack, and remove it from the
     * stack.  
     */
    public Node popNode() {
        return currentNodeScope.pop();
    }

    /** 
     * Returns the node currently on the top of the stack. 
     */
    public Node peekNode() {
        return currentNodeScope.peek();
    }

    /**
     * Puts the node on the top of the stack. However, unlike pushNode()
     * it replaces the node that is currently on the top of the stack.
     * This is effectively equivalent to popNode() followed by pushNode(n)
     */
    public void pokeNode(Node n) {
        currentNodeScope.poke(n);
    }

    /** Returns the number of children on the stack in the current node
	 * scope. 
	 */
    public int nodeArity() {
        return currentNodeScope.size();
    }

    public void clearNodeScope() {
        currentNodeScope.clear();
    }

    public void openNodeScope(Node n) {
        Token start= getToken(1);
        n.setBeginLine(start.getBeginLine());
        n.setBeginColumn(start.getBeginColumn());
        n.setInputSource(token_source.input_stream);
        new NodeScope();
        n.open();
        if (trace_enabled) LOGGER.info("Opened node scope for node of type: "+n.getClass().getName());
        if (trace_enabled) LOGGER.info("Scope nesting level is "+currentNodeScope.nestingLevel());
    }

    /* A definite node is constructed from a specified number of
	 * children.  That number of nodes are popped from the stack and
	 * made the children of the definite node.  Then the definite node
	 * is pushed on to the stack.
	 */
    public void closeNodeScope(Node n, int num) {
        n.setEndLine(current_token.getEndLine());
        n.setEndColumn(current_token.getEndColumn());
        if (trace_enabled) LOGGER.info("Closing node scope for node of type: "+n.getClass().getName()+", popping "+num+" nodes off the stack.");
        currentNodeScope.close();
        ArrayList<Node> nodes= new ArrayList<Node> ();
        for (int i= 0; i<num; i++) {
            nodes.add(popNode());
        }
        Collections.reverse(nodes);
        for (Node child : nodes) {
            if (unparsedTokensAreNodes&&(child instanceof Token)) {
                Token token= (Token) child;
                Token specialToken= token;
                while (specialToken!=null) {
                    specialToken= specialToken.getSpecialToken();
                }
                while (specialToken!=null&&specialToken!=token) {
                    n.addChild(specialToken);
                    specialToken= specialToken.getNext();
                }
            }
            n.addChild(child);
        }
        n.close();
        pushNode(n);
    }

    /**
	 * A conditional node is constructed if the condition is true.  All
	 * the nodes that have been pushed since the node was opened are
	 * made children of the conditional node, which is then pushed
	 * on to the stack.  If the condition is false the node is not
	 * constructed and they are left on the stack. 
	 */
    public void closeNodeScope(Node n, boolean condition) {
        n.setEndLine(current_token.getEndLine());
        n.setEndColumn(current_token.getEndColumn());
        if (condition) {
            if (trace_enabled) LOGGER.finer("Closing node scope for node of type: "+n.getClass().getName()+", popping "+nodeArity()+" nodes off the stack.");
            int a= nodeArity();
            currentNodeScope.close();
            ArrayList<Node> nodes= new ArrayList<Node> ();
            while (a--> 0) {
                nodes.add(popNode());
            }
            Collections.reverse(nodes);
            for (Node child : nodes) {
                if (unparsedTokensAreNodes&&(child instanceof Token)) {
                    Token token= (Token) child;
                    Token specialToken= token;
                    while (specialToken.getSpecialToken()!=null) {
                        specialToken= specialToken.getSpecialToken();
                    }
                    while (specialToken!=null&&specialToken!=token) {
                        n.addChild(specialToken);
                        specialToken= specialToken.getNext();
                    }
                }
                n.addChild(child);
            }
            n.close();
            if (trace_enabled) {
                LOGGER.info("Closing node scope for node of type: "+n.getClass().getName()+", leaving "+nodeArity()+" nodes on the stack.");
                LOGGER.info("Nesting level is : "+currentNodeScope.nestingLevel());
            }
            pushNode(n);
            if (trace_enabled) {
                LOGGER.info("Closed node scope for node of type: "+n.getClass().getName()+", there are now "+nodeArity()+" nodes on the stack.");
                LOGGER.info("Nesting level is : "+currentNodeScope.nestingLevel());
            }
        }
        else {
            currentNodeScope.close();
            if (trace_enabled) {
                LOGGER.info("Closed node scope for node of type: "+n.getClass().getName()+", leaving "+nodeArity()+" nodes on the stack.");
                LOGGER.info("Nesting level is : "+currentNodeScope.nestingLevel());
            }
        }
    }

    public boolean getBuildTree() {
        return buildTree;
    }

    public void setBuildTree(boolean buildTree) {
        this.buildTree= buildTree;
    }

    /**
     * Just a kludge so that existing jjtree-based code that uses
     * parser.jjtree.foo can work without change.
     */
    NewAwkParser jjtree= this;
    @SuppressWarnings("serial")
    class NodeScope extends ArrayList<Node>  {
        NodeScope parentScope;
        NodeScope() {
            this.parentScope= NewAwkParser.this.currentNodeScope;
            NewAwkParser.this.currentNodeScope= this;
        }

        boolean isRootScope() {
            return parentScope== null;
        }

        Node rootNode() {
            NodeScope ns= this;
            while (ns.parentScope!=null) {
                ns= ns.parentScope;
            }
            return ns.isEmpty()?null:
            ns.get(0);
        }

        Node peek() {
            return isEmpty()?parentScope.peek():
            get(size()-1);
        }

        Node pop() {
            return isEmpty()?parentScope.pop():
            remove(size()-1);
        }

        void poke(Node n) {
            if (isEmpty()) {
                parentScope.poke(n);
            }
            else {
                set(size()-1, n);
            }
        }

        void close() {
            parentScope.addAll(this);
            NewAwkParser.this.currentNodeScope= parentScope;
        }

        int nestingLevel() {
            int result= 0;
            NodeScope parent= this;
            while (parent.parentScope!=null) {
                result++;
                parent= parent.parentScope;
            }
            return result;
        }

    }
}
